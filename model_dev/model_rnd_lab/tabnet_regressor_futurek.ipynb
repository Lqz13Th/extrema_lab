{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b8fa6e-dbf1-4b27-bf9b-614e79efe11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已添加项目根目录到 sys.path: C:\\quant\\work\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def add_project_root(project_name: str = \"extrema_lab\"):\n",
    "    cwd = os.getcwd()\n",
    "    path_parts = cwd.split(os.sep)\n",
    "\n",
    "    for i in range(len(path_parts), 0, -1):\n",
    "        potential_root = os.sep.join(path_parts[:i])\n",
    "        if os.path.basename(potential_root) == project_name:\n",
    "            root = os.path.dirname(potential_root)\n",
    "            if root not in sys.path:\n",
    "                sys.path.append(root)\n",
    "            print(f\"已添加项目根目录到 sys.path: {root}\")\n",
    "            return\n",
    "\n",
    "    print(f\"未找到项目 {project_name}，请确认路径是否正确\")\n",
    "\n",
    "\n",
    "add_project_root(\"extrema_lab\")\n",
    "from extrema_lab.feature_eng.operator.utils_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57543a8-ec79-4281-b87f-b93b4b39a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"BTCUSDT\"\n",
    "threshold = 0.0031\n",
    "feat_cal_window = 600\n",
    "feat_norm_window = 600\n",
    "feat_norm_rolling_mean_window = 300\n",
    "\n",
    "origin_df = process_single_symbol(\n",
    "    symbol,\n",
    "    str(threshold),\n",
    "    feat_cal_window,\n",
    "    feat_norm_window,\n",
    "    feat_norm_rolling_mean_window,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad897b3-daf0-4452-ae76-2dbc0aae64d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (27_572, 267)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>px</th><th>sum_buy_sz</th><th>sum_sell_sz</th><th>ts_duration</th><th>px_pct</th><th>bs_imbalance</th><th>oi_sum_open_interest</th><th>oi_sum_open_interest_value</th><th>funding_funding_interval_hours</th><th>funding_last_funding_rate</th><th>premium_open</th><th>adjusted_funding_rate</th><th>funding_oi</th><th>premium_oi</th><th>funding_premium</th><th>factor_triplet</th><th>premium_funding_spread</th><th>oi_sum_open_interest_value_roll_mean_ratio_12</th><th>oi_sum_open_interest_value_pct_change_sum_12</th><th>oi_sum_open_interest_value_roll_mean_ratio_72</th><th>oi_sum_open_interest_value_pct_change_sum_72</th><th>oi_sum_open_interest_value_roll_mean_ratio_144</th><th>oi_sum_open_interest_value_pct_change_sum_144</th><th>oi_sum_open_interest_value_roll_mean_ratio_288</th><th>oi_sum_open_interest_value_pct_change_sum_288</th><th>premium_funding_spread_sum_288</th><th>adjusted_funding_rate_sum_288</th><th>premium_open_sum_288</th><th>funding_oi_roll_mean_ratio_288</th><th>premium_oi_roll_mean_ratio_288</th><th>factor_triplet_roll_mean_ratio_288</th><th>premium_oi_dev_144</th><th>z_oi_sum_open_interest</th><th>z_oi_sum_open_interest_value</th><th>z_funding_oi</th><th>z_premium_oi</th><th>&hellip;</th><th>z_oi_up_divergence_short_term_zscaled</th><th>z_oi_dn_divergence_short_term_zscaled</th><th>z_sum_sz_px_pct_rol_sum_600_zscaled</th><th>z_px_velo_rol_mean_600_zscaled</th><th>z_oi_px_diff_600_zscaled</th><th>oi_di_zscaled</th><th>oi_di_long_term_zscaled</th><th>oi_di_short_term_zscaled</th><th>taker_px_pct_diff_zscaled</th><th>factor_impact_momentum_zscaled</th><th>factor_impact_sensitivity_zscaled</th><th>factor_orderflow_sz_momentum_zscaled</th><th>factor_orderflow_sz_sensitivity_zscaled</th><th>z_oi_di_zscaled</th><th>z_oi_di_long_term_zscaled</th><th>z_taker_px_pct_diff_zscaled</th><th>z_factor_impact_momentum_zscaled</th><th>z_factor_impact_sensitivity_zscaled</th><th>z_factor_orderflow_sz_momentum_zscaled</th><th>z_factor_orderflow_sz_sensitivity_zscaled</th><th>factor_order_momentum_divergence_zscaled</th><th>factor_order_sentiment_divergence_zscaled</th><th>corr_px_oi_sum_open_interest_value_600_zscaled</th><th>z_signal_px_oi_sum_open_interest_value_600_zscaled</th><th>z_factor_order_momentum_divergence_zscaled</th><th>z_factor_order_sentiment_divergence_zscaled</th><th>z_corr_px_oi_sum_open_interest_value_600_zscaled</th><th>px_risk_factor_zscaled</th><th>px_drawdown_zscaled</th><th>px_rebound_zscaled</th><th>z_px_risk_factor_zscaled</th><th>z_px_drawdown_zscaled</th><th>z_px_rebound_zscaled</th><th>px_dd_rb_zscaled</th><th>micro_trend_factor_600_zscaled</th><th>z_px_dd_rb_zscaled</th><th>z_micro_trend_factor_600_zscaled</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1719794346863000</td><td>62765.4</td><td>1469.862</td><td>989.364</td><td>1.6274e9</td><td>0.0031</td><td>480.498</td><td>1.7789225e7</td><td>28379.754893</td><td>8.0</td><td>0.0001</td><td>-0.000452</td><td>0.0000125</td><td>0.354747</td><td>-12.818568</td><td>-5.6460e-9</td><td>-0.00016</td><td>-0.000464</td><td>1.001977</td><td>0.005286</td><td>1.008207</td><td>0.033213</td><td>1.018718</td><td>0.02563</td><td>1.019522</td><td>0.020398</td><td>-0.133684</td><td>0.0036</td><td>-0.130084</td><td>1.019522</td><td>1.019522</td><td>1.019522</td><td>0.018718</td><td>2.589929</td><td>2.142257</td><td>2.14225</td><td>-2.142256</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>1719795609089000</td><td>62960.0</td><td>1252.314</td><td>1049.962</td><td>1.2622e9</td><td>0.0031</td><td>202.352</td><td>1.7807281e7</td><td>28351.576512</td><td>8.0</td><td>0.0001</td><td>-0.000452</td><td>0.0000125</td><td>0.354395</td><td>-12.80584</td><td>-5.6460e-9</td><td>-0.00016</td><td>-0.000464</td><td>0.999358</td><td>0.002151</td><td>1.004922</td><td>0.033643</td><td>1.016889</td><td>0.02351</td><td>1.01816</td><td>0.019744</td><td>-0.133684</td><td>0.0036</td><td>-0.130084</td><td>1.01816</td><td>1.01816</td><td>1.01816</td><td>0.016889</td><td>2.473075</td><td>1.926233</td><td>1.926227</td><td>-1.926233</td><td>&hellip;</td><td>0.0</td><td>-0.30443</td><td>0.30443</td><td>0.30443</td><td>-0.30443</td><td>-0.30443</td><td>0.225951</td><td>0.12611</td><td>0.30443</td><td>0.30443</td><td>0.30443</td><td>0.30443</td><td>0.30443</td><td>-0.30443</td><td>-0.30443</td><td>0.30443</td><td>0.30443</td><td>0.30443</td><td>0.30443</td><td>0.30443</td><td>-0.304419</td><td>-0.30443</td><td>-0.30443</td><td>0.0</td><td>-0.30443</td><td>-0.30443</td><td>-0.30443</td><td>0.30443</td><td>0.0</td><td>0.30443</td><td>0.30443</td><td>0.0</td><td>0.30443</td><td>0.30443</td><td>0.0</td><td>0.30443</td><td>0.0</td></tr><tr><td>1719795974168000</td><td>63155.6</td><td>1241.123</td><td>585.889</td><td>3.65079e8</td><td>0.003107</td><td>655.234</td><td>1.7807919e7</td><td>28311.282941</td><td>8.0</td><td>0.0001</td><td>-0.000452</td><td>0.0000125</td><td>0.353891</td><td>-12.78764</td><td>-5.6460e-9</td><td>-0.00016</td><td>-0.000464</td><td>0.998</td><td>-0.000738</td><td>1.003202</td><td>0.021283</td><td>1.015288</td><td>0.022267</td><td>1.016651</td><td>0.017816</td><td>-0.133684</td><td>0.0036</td><td>-0.130084</td><td>1.016651</td><td>1.016651</td><td>1.016651</td><td>0.015288</td><td>2.440611</td><td>1.756726</td><td>1.756721</td><td>-1.756726</td><td>&hellip;</td><td>0.273102</td><td>-0.442811</td><td>0.437797</td><td>0.433712</td><td>-0.411422</td><td>-0.442842</td><td>0.26913</td><td>0.356697</td><td>0.472709</td><td>0.433538</td><td>0.44588</td><td>0.327896</td><td>0.385808</td><td>-0.448176</td><td>-0.442849</td><td>0.472825</td><td>0.367635</td><td>0.432508</td><td>0.304605</td><td>0.343355</td><td>-0.304439</td><td>-0.332784</td><td>-0.454591</td><td>0.0</td><td>-0.277471</td><td>-0.303876</td><td>-0.443999</td><td>0.456729</td><td>0.0</td><td>0.456937</td><td>0.431185</td><td>0.0</td><td>0.440536</td><td>0.440536</td><td>0.0</td><td>0.411322</td><td>0.0</td></tr><tr><td>1719795977521000</td><td>63351.4</td><td>1442.882</td><td>184.21</td><td>3.353e6</td><td>0.0031</td><td>1258.672</td><td>1.7807919e7</td><td>28311.282941</td><td>8.0</td><td>0.0001</td><td>-0.000452</td><td>0.0000125</td><td>0.353891</td><td>-12.78764</td><td>-5.6460e-9</td><td>-0.00016</td><td>-0.000464</td><td>0.998</td><td>-0.000738</td><td>1.003202</td><td>0.021283</td><td>1.015288</td><td>0.022267</td><td>1.016651</td><td>0.017816</td><td>-0.133684</td><td>0.0036</td><td>-0.130084</td><td>1.016651</td><td>1.016651</td><td>1.016651</td><td>0.015288</td><td>2.440611</td><td>1.756726</td><td>1.756721</td><td>-1.756726</td><td>&hellip;</td><td>0.37296</td><td>-0.520508</td><td>0.512065</td><td>0.400325</td><td>-0.366815</td><td>-0.520553</td><td>0.275841</td><td>0.473022</td><td>0.575066</td><td>0.504568</td><td>0.523565</td><td>0.10612</td><td>0.294929</td><td>-0.530915</td><td>-0.520563</td><td>0.561335</td><td>0.347605</td><td>0.480513</td><td>0.080297</td><td>0.22006</td><td>-0.080329</td><td>-0.219068</td><td>-0.516116</td><td>-0.226287</td><td>-0.035115</td><td>-0.143632</td><td>-0.477338</td><td>0.547817</td><td>0.0</td><td>0.548201</td><td>0.497974</td><td>0.0</td><td>0.515486</td><td>0.515486</td><td>0.0</td><td>0.440833</td><td>0.0</td></tr><tr><td>1719795980392000</td><td>63155.0</td><td>197.033</td><td>191.229</td><td>2.871e6</td><td>-0.0031</td><td>5.804</td><td>1.7807919e7</td><td>28311.282941</td><td>8.0</td><td>0.0001</td><td>-0.000452</td><td>0.0000125</td><td>0.353891</td><td>-12.78764</td><td>-5.6460e-9</td><td>-0.00016</td><td>-0.000464</td><td>0.998</td><td>-0.000738</td><td>1.003202</td><td>0.021283</td><td>1.015288</td><td>0.022267</td><td>1.016651</td><td>0.017816</td><td>-0.133684</td><td>0.0036</td><td>-0.130084</td><td>1.016651</td><td>1.016651</td><td>1.016651</td><td>0.015288</td><td>2.440611</td><td>1.756726</td><td>1.756721</td><td>-1.756726</td><td>&hellip;</td><td>0.27633</td><td>-0.569654</td><td>0.229164</td><td>0.13934</td><td>-0.284838</td><td>-0.569704</td><td>0.271698</td><td>0.462173</td><td>0.615931</td><td>0.22472</td><td>0.272635</td><td>-0.097504</td><td>0.054617</td><td>-0.58414</td><td>-0.569715</td><td>0.490469</td><td>0.089073</td><td>0.195868</td><td>-0.108621</td><td>-0.000372</td><td>0.10855</td><td>-0.002214</td><td>-0.53999</td><td>-0.340801</td><td>0.13719</td><td>0.059601</td><td>-0.465259</td><td>0.562969</td><td>0.189128</td><td>0.505503</td><td>0.403484</td><td>0.189128</td><td>0.242094</td><td>0.601192</td><td>0.0</td><td>0.541482</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1753998798318000</td><td>116308.2</td><td>6258.555</td><td>6991.702</td><td>6.4551e9</td><td>-0.0031</td><td>-733.147</td><td>3.2291094e7</td><td>27672.967664</td><td>8.0</td><td>0.0001</td><td>-0.000452</td><td>0.0000125</td><td>0.345912</td><td>-12.499326</td><td>-5.6460e-9</td><td>-0.000156</td><td>-0.000464</td><td>1.003458</td><td>0.005392</td><td>1.035667</td><td>0.049525</td><td>1.04069</td><td>0.040538</td><td>1.03445</td><td>0.011802</td><td>-0.133684</td><td>0.0036</td><td>-0.130084</td><td>1.03445</td><td>1.03445</td><td>1.03445</td><td>0.04069</td><td>1.902013</td><td>2.418186</td><td>2.418181</td><td>-2.418186</td><td>&hellip;</td><td>-0.38912</td><td>-0.821008</td><td>-0.940812</td><td>-0.943901</td><td>-0.343027</td><td>-0.378036</td><td>-0.199536</td><td>-0.213236</td><td>-0.826678</td><td>-0.944441</td><td>-0.938485</td><td>-0.042118</td><td>0.585558</td><td>-0.394321</td><td>-0.439815</td><td>-0.960494</td><td>-0.842091</td><td>-0.835205</td><td>-0.085469</td><td>0.284537</td><td>0.091189</td><td>0.007804</td><td>0.236827</td><td>0.487584</td><td>0.059863</td><td>0.077302</td><td>-0.88195</td><td>-0.708158</td><td>0.571843</td><td>-0.818215</td><td>-0.930005</td><td>0.435346</td><td>-0.924664</td><td>-0.286943</td><td>0.097309</td><td>-0.476574</td><td>0.039363</td></tr><tr><td>1754002792035000</td><td>115947.6</td><td>3892.009</td><td>5099.169</td><td>3.9937e9</td><td>-0.0031</td><td>-1207.16</td><td>3.2199948e7</td><td>27748.081725</td><td>8.0</td><td>0.0001</td><td>-0.000452</td><td>0.0000125</td><td>0.346851</td><td>-12.533254</td><td>-5.6460e-9</td><td>-0.000157</td><td>-0.000464</td><td>1.000298</td><td>0.002069</td><td>1.028198</td><td>0.062699</td><td>1.039266</td><td>0.047294</td><td>1.036432</td><td>0.019945</td><td>-0.133684</td><td>0.0036</td><td>-0.130084</td><td>1.036432</td><td>1.036432</td><td>1.036432</td><td>0.039266</td><td>1.559043</td><td>2.319596</td><td>2.319592</td><td>-2.319596</td><td>&hellip;</td><td>-0.388851</td><td>-0.821289</td><td>-0.940759</td><td>-0.943881</td><td>-0.344652</td><td>-0.379214</td><td>-0.20027</td><td>-0.213591</td><td>-0.829608</td><td>-0.944455</td><td>-0.93833</td><td>-0.037738</td><td>0.582952</td><td>-0.395071</td><td>-0.439717</td><td>-0.959922</td><td>-0.840817</td><td>-0.833241</td><td>-0.080646</td><td>0.283904</td><td>0.086186</td><td>0.010484</td><td>0.230585</td><td>0.48506</td><td>0.054884</td><td>0.078829</td><td>-0.883204</td><td>-0.711961</td><td>0.571768</td><td>-0.819404</td><td>-0.929614</td><td>0.434856</td><td>-0.9242</td><td>-0.289986</td><td>0.09934</td><td>-0.479855</td><td>0.040906</td></tr><tr><td>1754003667224000</td><td>116307.1</td><td>1484.396</td><td>1485.197</td><td>8.75189e8</td><td>0.003101</td><td>-0.801</td><td>3.2300265e7</td><td>27822.682198</td><td>8.0</td><td>0.0001</td><td>-0.000452</td><td>0.0000125</td><td>0.347784</td><td>-12.566949</td><td>-5.6460e-9</td><td>-0.000157</td><td>-0.000464</td><td>1.00261</td><td>0.002154</td><td>1.028229</td><td>0.064424</td><td>1.041002</td><td>0.050122</td><td>1.038985</td><td>0.023364</td><td>-0.133684</td><td>0.0036</td><td>-0.130084</td><td>1.038985</td><td>1.038985</td><td>1.038985</td><td>0.041002</td><td>1.789387</td><td>2.42409</td><td>2.424085</td><td>-2.42409</td><td>&hellip;</td><td>-0.391016</td><td>-0.821624</td><td>-0.940655</td><td>-0.94381</td><td>-0.346023</td><td>-0.380396</td><td>-0.20149</td><td>-0.216625</td><td>-0.832391</td><td>-0.944326</td><td>-0.938238</td><td>-0.033075</td><td>0.580918</td><td>-0.395826</td><td>-0.439918</td><td>-0.959341</td><td>-0.839015</td><td>-0.831673</td><td>-0.075647</td><td>0.283625</td><td>0.081021</td><td>0.012617</td><td>0.224341</td><td>0.482541</td><td>0.049791</td><td>0.079629</td><td>-0.884432</td><td>-0.715737</td><td>0.571443</td><td>-0.820416</td><td>-0.929211</td><td>0.433915</td><td>-0.923674</td><td>-0.293949</td><td>0.102067</td><td>-0.483897</td><td>0.042954</td></tr><tr><td>1754004696776000</td><td>115946.5</td><td>550.981</td><td>610.676</td><td>1.0296e9</td><td>-0.0031</td><td>-59.695</td><td>3.2424256e7</td><td>27924.958725</td><td>8.0</td><td>0.0001</td><td>-0.000452</td><td>0.0000125</td><td>0.349062</td><td>-12.613145</td><td>-5.6460e-9</td><td>-0.000158</td><td>-0.000464</td><td>1.004742</td><td>0.005106</td><td>1.028207</td><td>0.067008</td><td>1.043276</td><td>0.053772</td><td>1.04241</td><td>0.027526</td><td>-0.133684</td><td>0.0036</td><td>-0.130084</td><td>1.04241</td><td>1.04241</td><td>1.04241</td><td>0.043276</td><td>2.036346</td><td>2.535192</td><td>2.535187</td><td>-2.535192</td><td>&hellip;</td><td>-0.392082</td><td>-0.822479</td><td>-0.940552</td><td>-0.943796</td><td>-0.34712</td><td>-0.38158</td><td>-0.202716</td><td>-0.219053</td><td>-0.835166</td><td>-0.944167</td><td>-0.938293</td><td>-0.029365</td><td>0.577667</td><td>-0.396582</td><td>-0.44015</td><td>-0.95876</td><td>-0.836905</td><td>-0.830649</td><td>-0.071424</td><td>0.282554</td><td>0.076636</td><td>0.015816</td><td>0.218097</td><td>0.480027</td><td>0.045271</td><td>0.081759</td><td>-0.885635</td><td>-0.719486</td><td>0.571372</td><td>-0.821593</td><td>-0.928795</td><td>0.433422</td><td>-0.923193</td><td>-0.296948</td><td>0.104084</td><td>-0.487115</td><td>0.044477</td></tr><tr><td>1754005233091000</td><td>115586.9</td><td>972.462</td><td>2105.639</td><td>5.36315e8</td><td>-0.003101</td><td>-1133.177</td><td>3.2466718e7</td><td>28011.031267</td><td>8.0</td><td>0.0001</td><td>-0.000452</td><td>0.0000125</td><td>0.350138</td><td>-12.652023</td><td>-5.6460e-9</td><td>-0.000158</td><td>-0.000464</td><td>1.006085</td><td>0.010774</td><td>1.029446</td><td>0.06934</td><td>1.045673</td><td>0.056712</td><td>1.045395</td><td>0.032558</td><td>-0.133684</td><td>0.0036</td><td>-0.130084</td><td>1.045395</td><td>1.045395</td><td>1.045395</td><td>0.045673</td><td>2.104219</td><td>2.654805</td><td>2.6548</td><td>-2.654804</td><td>&hellip;</td><td>-0.391906</td><td>-0.823338</td><td>-0.940524</td><td>-0.943831</td><td>-0.347937</td><td>-0.382764</td><td>-0.20467</td><td>-0.220687</td><td>-0.838041</td><td>-0.944192</td><td>-0.938347</td><td>-0.02609</td><td>0.573692</td><td>-0.39734</td><td>-0.440865</td><td>-0.958202</td><td>-0.835442</td><td>-0.829348</td><td>-0.067564</td><td>0.280642</td><td>0.072631</td><td>0.019471</td><td>0.211854</td><td>0.477518</td><td>0.04102</td><td>0.084529</td><td>-0.886813</td><td>-0.723204</td><td>0.571539</td><td>-0.822951</td><td>-0.928365</td><td>0.433256</td><td>-0.922758</td><td>-0.298905</td><td>0.105422</td><td>-0.489394</td><td>0.045528</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (27_572, 267)\n",
       "┌──────────────────┬──────────┬────────────┬─────────────┬───┬──────────────────┬──────────────────────┬────────────────────┬─────────────────────┐\n",
       "│ timestamp        ┆ px       ┆ sum_buy_sz ┆ sum_sell_sz ┆ … ┆ px_dd_rb_zscaled ┆ micro_trend_factor_6 ┆ z_px_dd_rb_zscaled ┆ z_micro_trend_facto │\n",
       "│ ---              ┆ ---      ┆ ---        ┆ ---         ┆   ┆ ---              ┆ 00_zscaled           ┆ ---                ┆ r_600_zscal…        │\n",
       "│ i64              ┆ f64      ┆ f64        ┆ f64         ┆   ┆ f64              ┆ ---                  ┆ f64                ┆ ---                 │\n",
       "│                  ┆          ┆            ┆             ┆   ┆                  ┆ f64                  ┆                    ┆ f64                 │\n",
       "╞══════════════════╪══════════╪════════════╪═════════════╪═══╪══════════════════╪══════════════════════╪════════════════════╪═════════════════════╡\n",
       "│ 1719794346863000 ┆ 62765.4  ┆ 1469.862   ┆ 989.364     ┆ … ┆ 0.0              ┆ 0.0                  ┆ 0.0                ┆ 0.0                 │\n",
       "│ 1719795609089000 ┆ 62960.0  ┆ 1252.314   ┆ 1049.962    ┆ … ┆ 0.30443          ┆ 0.0                  ┆ 0.30443            ┆ 0.0                 │\n",
       "│ 1719795974168000 ┆ 63155.6  ┆ 1241.123   ┆ 585.889     ┆ … ┆ 0.440536         ┆ 0.0                  ┆ 0.411322           ┆ 0.0                 │\n",
       "│ 1719795977521000 ┆ 63351.4  ┆ 1442.882   ┆ 184.21      ┆ … ┆ 0.515486         ┆ 0.0                  ┆ 0.440833           ┆ 0.0                 │\n",
       "│ 1719795980392000 ┆ 63155.0  ┆ 197.033    ┆ 191.229     ┆ … ┆ 0.601192         ┆ 0.0                  ┆ 0.541482           ┆ 0.0                 │\n",
       "│ …                ┆ …        ┆ …          ┆ …           ┆ … ┆ …                ┆ …                    ┆ …                  ┆ …                   │\n",
       "│ 1753998798318000 ┆ 116308.2 ┆ 6258.555   ┆ 6991.702    ┆ … ┆ -0.286943        ┆ 0.097309             ┆ -0.476574          ┆ 0.039363            │\n",
       "│ 1754002792035000 ┆ 115947.6 ┆ 3892.009   ┆ 5099.169    ┆ … ┆ -0.289986        ┆ 0.09934              ┆ -0.479855          ┆ 0.040906            │\n",
       "│ 1754003667224000 ┆ 116307.1 ┆ 1484.396   ┆ 1485.197    ┆ … ┆ -0.293949        ┆ 0.102067             ┆ -0.483897          ┆ 0.042954            │\n",
       "│ 1754004696776000 ┆ 115946.5 ┆ 550.981    ┆ 610.676     ┆ … ┆ -0.296948        ┆ 0.104084             ┆ -0.487115          ┆ 0.044477            │\n",
       "│ 1754005233091000 ┆ 115586.9 ┆ 972.462    ┆ 2105.639    ┆ … ┆ -0.298905        ┆ 0.105422             ┆ -0.489394          ┆ 0.045528            │\n",
       "└──────────────────┴──────────┴────────────┴─────────────┴───┴──────────────────┴──────────────────────┴────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81488d5c-c198-4ae6-befe-73543b3dc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9cb814c-053d-4ad7-94b8-82bad439912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_last_n_rows_with_px_regression(\n",
    "    y_true,           # 真实未来收益率\n",
    "    y_pred,           # 模型预测收益率\n",
    "    px,               # 价格\n",
    "    std_array=None,   # 可选标准差\n",
    "    n=700,\n",
    "    m=-1,\n",
    "    alpha=1.0\n",
    "):\n",
    "    # 截取最近 n 行\n",
    "    y_true_slice = y_true[n:m]\n",
    "    y_pred_slice = y_pred[n:m]\n",
    "    px_slice = px[n:m]\n",
    "    std_slice = std_array[n:m] if std_array is not None else None\n",
    "\n",
    "    time_index = np.arange(len(y_true_slice))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "    # 价格线\n",
    "    ax1.plot(time_index, px_slice, color='tab:gray', label='Price (px)', linewidth=1.5)\n",
    "    if std_slice is not None:\n",
    "        ax1.plot(time_index, px_slice + alpha * std_slice, linestyle=':', color='gray', alpha=0.4, label='+std')\n",
    "        ax1.plot(time_index, px_slice - alpha * std_slice, linestyle=':', color='gray', alpha=0.4, label='-std')\n",
    "\n",
    "    ax1.set_ylabel(\"Price\")\n",
    "    ax1.set_xlabel(\"Time Index\")\n",
    "    ax1.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "    # 创建第二个 y 轴：收益率\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(time_index, y_true_slice, label='True Future Return', color='tab:blue', linewidth=1.5)\n",
    "    ax2.plot(time_index, y_pred_slice, label='Predicted Return', color='tab:green', linestyle='--', linewidth=1.5)\n",
    "    ax2.set_ylabel(\"Return\")\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "    # 图例\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "    plt.title(f\"Price, True Return, and Predicted Return (Last {n} rows)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "619e028e-562e-41bd-873e-3ea5062208b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating future returns: 100%|██████████████████████████████████████████████████████████████████████| 27422/27422 [00:00<00:00, 1305207.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted\n",
      "各列空值数量：\n",
      "future_return    150\n",
      "dtype: int64\n",
      "删除空值超过 500000 的列：[]\n",
      "删除列后，DataFrame形状：(27572, 268)\n",
      "删除空值行后，DataFrame形状：(27422, 268)\n",
      "num split dfs:  13\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "future_window = 150 # 改成预测未来150步的收益率\n",
    "\n",
    "# 假设你已经有了 origin_df\n",
    "px_np = origin_df[\"px\"].to_numpy()\n",
    "\n",
    "def future_return(px: np.ndarray, window: int, use_log_return: bool = False) -> np.ndarray:\n",
    "    n = len(px)\n",
    "    returns = np.full(n, np.nan)\n",
    "\n",
    "    for i in tqdm(range(n - window), desc=\"Calculating future returns\"):\n",
    "        if use_log_return:\n",
    "            returns[i] = np.log(px[i + window] / px[i]) if px[i] > 0 else np.nan\n",
    "        else:\n",
    "            returns[i] = (px[i + window] - px[i]) / px[i] if px[i] > 0 else np.nan\n",
    "\n",
    "    return returns\n",
    "\n",
    "# 计算未来收益率标签\n",
    "future_return_label = future_return(px_np, future_window, use_log_return=True)\n",
    "\n",
    "# 加入 DataFrame\n",
    "a_df = origin_df.with_columns([\n",
    "    pl.Series(\"future_return\", future_return_label)\n",
    "])\n",
    "\n",
    "# 去除 NaN\n",
    "a_df_filtered = a_df.filter(pl.col(\"future_return\").is_not_null())\n",
    "a_df_filtered = clean_df_drop_nulls(a_df_filtered)\n",
    "\n",
    "# 可选：按周分割\n",
    "split_dataframes = split_df_by_month(a_df_filtered)\n",
    "print(\"num split dfs: \", len(split_dataframes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e96f540-b9aa-482e-b67a-9b08e2ed4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def save_tabnet_checkpoint(\n",
    "    model,\n",
    "    symbol,\n",
    "    base_save_dir: str,\n",
    "    model_params: dict,\n",
    "    feature_names: list[str],\n",
    "    training_meta: dict,\n",
    "    unique_id: str = None, \n",
    "):\n",
    "    if unique_id is None:\n",
    "        timestamp = str(datetime.now().strftime(\"%Y-%m-%d_%H-%M\"))\n",
    "        save_dir = os.path.join(base_save_dir, f\"{symbol}_{timestamp}\")\n",
    "    else:\n",
    "        save_dir = os.path.join(base_save_dir, f\"{symbol}_{unique_id}\")\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    model_path = os.path.join(save_dir, \"tabnet_model\")\n",
    "    model.save_model(model_path)\n",
    "\n",
    "    config_path = os.path.join(save_dir, \"model_metadata.json\")\n",
    "    with open(config_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"model_params\": model_params,\n",
    "            \"meta_info\": training_meta,\n",
    "        }, f, indent=4)\n",
    "\n",
    "    aux_path = os.path.join(save_dir, \"auxiliary.pkl\")\n",
    "    with open(aux_path, \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"feature_names\": feature_names,\n",
    "        }, f)\n",
    "\n",
    "    print(f\"model and meta info saved to {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c277b3bf-134d-4f40-842d-91c7915a676b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "============================================================\n",
      "Fold 0: Train 0~5, Val 6\n",
      "Train: 2024-07-01 00:39:06.863000 to 2024-12-31 22:21:59.887000\n",
      "Val: 2025-01-01 00:20:58.659000 to 2025-01-31 22:52:45.838000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.9352  |  0:00:00s\n",
      "epoch 20 | loss: 0.00297 |  0:00:05s\n",
      "epoch 40 | loss: 0.00174 |  0:00:11s\n",
      "epoch 60 | loss: 0.00113 |  0:00:16s\n",
      "epoch 80 | loss: 0.00088 |  0:00:21s\n",
      "epoch 100| loss: 0.0007  |  0:00:27s\n",
      "epoch 120| loss: 0.00059 |  0:00:32s\n",
      "epoch 140| loss: 0.00046 |  0:00:37s\n",
      "epoch 160| loss: 0.0005  |  0:00:42s\n",
      "epoch 180| loss: 0.00048 |  0:00:48s\n",
      "epoch 200| loss: 0.00037 |  0:00:54s\n",
      "epoch 220| loss: 0.00039 |  0:00:59s\n",
      "epoch 240| loss: 0.0003  |  0:01:05s\n",
      "epoch 260| loss: 0.00027 |  0:01:10s\n",
      "epoch 280| loss: 0.00031 |  0:01:15s\n",
      "epoch 300| loss: 0.00023 |  0:01:20s\n",
      "epoch 320| loss: 0.00022 |  0:01:25s\n",
      "epoch 340| loss: 0.00022 |  0:01:30s\n",
      "epoch 360| loss: 0.00021 |  0:01:36s\n",
      "epoch 380| loss: 0.0002  |  0:01:41s\n",
      "epoch 400| loss: 0.00017 |  0:01:46s\n",
      "epoch 420| loss: 0.00019 |  0:01:52s\n",
      "epoch 440| loss: 0.00019 |  0:01:57s\n",
      "epoch 460| loss: 0.00015 |  0:02:02s\n",
      "epoch 480| loss: 0.00016 |  0:02:08s\n",
      "epoch 500| loss: 0.00016 |  0:02:13s\n",
      "epoch 520| loss: 0.00014 |  0:02:18s\n",
      "epoch 540| loss: 0.00013 |  0:02:23s\n",
      "epoch 560| loss: 0.00014 |  0:02:28s\n",
      "epoch 580| loss: 0.00015 |  0:02:33s\n",
      "回归评估 (Val):\n",
      "MSE: 0.0021591411711546307\n",
      "MAE: 0.037760244909246565\n",
      "R²: -0.45603898100379103\n",
      "IC (val): 0.08688458313575478\n",
      "过滤高置信度样本数量:  2100\n",
      "Test Week 6 Evaluation Completed\n",
      "============================================================\n",
      "Fold 1: Train 1~6, Val 7\n",
      "Train: 2024-08-01 00:27:23.613000 to 2025-01-31 22:52:45.838000\n",
      "Val: 2025-02-01 01:37:25.071000 to 2025-02-28 23:41:35.351000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.7933  |  0:00:00s\n",
      "epoch 20 | loss: 0.00254 |  0:00:05s\n",
      "epoch 40 | loss: 0.00134 |  0:00:10s\n",
      "epoch 60 | loss: 0.00108 |  0:00:15s\n",
      "epoch 80 | loss: 0.00073 |  0:00:21s\n",
      "epoch 100| loss: 0.00069 |  0:00:26s\n",
      "epoch 120| loss: 0.00057 |  0:00:31s\n",
      "epoch 140| loss: 0.00053 |  0:00:36s\n",
      "epoch 160| loss: 0.00039 |  0:00:41s\n",
      "epoch 180| loss: 0.00043 |  0:00:46s\n",
      "epoch 200| loss: 0.00049 |  0:00:52s\n",
      "epoch 220| loss: 0.00032 |  0:00:57s\n",
      "epoch 240| loss: 0.00024 |  0:01:03s\n",
      "epoch 260| loss: 0.0003  |  0:01:09s\n",
      "epoch 280| loss: 0.00023 |  0:01:15s\n",
      "epoch 300| loss: 0.00026 |  0:01:21s\n",
      "epoch 320| loss: 0.00021 |  0:01:26s\n",
      "epoch 340| loss: 0.00021 |  0:01:32s\n",
      "epoch 360| loss: 0.00017 |  0:01:38s\n",
      "epoch 380| loss: 0.00018 |  0:01:43s\n",
      "epoch 400| loss: 0.00019 |  0:01:49s\n",
      "epoch 420| loss: 0.00017 |  0:01:55s\n",
      "epoch 440| loss: 0.00018 |  0:02:01s\n",
      "epoch 460| loss: 0.00017 |  0:02:06s\n",
      "epoch 480| loss: 0.00017 |  0:02:11s\n",
      "epoch 500| loss: 0.00016 |  0:02:17s\n",
      "epoch 520| loss: 0.00016 |  0:02:22s\n",
      "epoch 540| loss: 0.00018 |  0:02:27s\n",
      "epoch 560| loss: 0.00014 |  0:02:33s\n",
      "epoch 580| loss: 0.00016 |  0:02:38s\n",
      "回归评估 (Val):\n",
      "MSE: 0.002065479278738624\n",
      "MAE: 0.03691748007843925\n",
      "R²: -0.4522444216241144\n",
      "IC (val): 0.16739987062425085\n",
      "过滤高置信度样本数量:  1968\n",
      "Test Week 7 Evaluation Completed\n",
      "============================================================\n",
      "Fold 2: Train 2~7, Val 8\n",
      "Train: 2024-09-01 02:06:22.227000 to 2025-02-28 23:41:35.351000\n",
      "Val: 2025-03-01 00:16:00.024000 to 2025-03-31 23:25:32.924000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.64249 |  0:00:00s\n",
      "epoch 20 | loss: 0.00403 |  0:00:04s\n",
      "epoch 40 | loss: 0.00235 |  0:00:09s\n",
      "epoch 60 | loss: 0.0015  |  0:00:14s\n",
      "epoch 80 | loss: 0.00108 |  0:00:18s\n",
      "epoch 100| loss: 0.00107 |  0:00:23s\n",
      "epoch 120| loss: 0.00081 |  0:00:28s\n",
      "epoch 140| loss: 0.0007  |  0:00:33s\n",
      "epoch 160| loss: 0.00059 |  0:00:38s\n",
      "epoch 180| loss: 0.00052 |  0:00:43s\n",
      "epoch 200| loss: 0.00047 |  0:00:48s\n",
      "epoch 220| loss: 0.00042 |  0:00:53s\n",
      "epoch 240| loss: 0.00036 |  0:00:58s\n",
      "epoch 260| loss: 0.00032 |  0:01:02s\n",
      "epoch 280| loss: 0.0003  |  0:01:07s\n",
      "epoch 300| loss: 0.00033 |  0:01:12s\n",
      "epoch 320| loss: 0.00031 |  0:01:16s\n",
      "epoch 340| loss: 0.00027 |  0:01:21s\n",
      "epoch 360| loss: 0.00027 |  0:01:26s\n",
      "epoch 380| loss: 0.00023 |  0:01:30s\n",
      "epoch 400| loss: 0.00022 |  0:01:35s\n",
      "epoch 420| loss: 0.0002  |  0:01:39s\n",
      "epoch 440| loss: 0.0002  |  0:01:44s\n",
      "epoch 460| loss: 0.00023 |  0:01:48s\n",
      "epoch 480| loss: 0.00021 |  0:01:52s\n",
      "epoch 500| loss: 0.00021 |  0:01:57s\n",
      "epoch 520| loss: 0.00022 |  0:02:01s\n",
      "epoch 540| loss: 0.00017 |  0:02:06s\n",
      "epoch 560| loss: 0.00015 |  0:02:10s\n",
      "epoch 580| loss: 0.00017 |  0:02:15s\n",
      "回归评估 (Val):\n",
      "MSE: 0.0029237932795002737\n",
      "MAE: 0.042961413576858586\n",
      "R²: -0.9479707978261753\n",
      "IC (val): 0.1591599405727785\n",
      "过滤高置信度样本数量:  2865\n",
      "Test Week 8 Evaluation Completed\n",
      "============================================================\n",
      "Fold 3: Train 3~8, Val 9\n",
      "Train: 2024-10-01 00:15:26.387000 to 2025-03-31 23:25:32.924000\n",
      "Val: 2025-04-01 00:52:10.681000 to 2025-04-30 22:44:06.281000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.36846 |  0:00:00s\n",
      "epoch 20 | loss: 0.00349 |  0:00:05s\n",
      "epoch 40 | loss: 0.00198 |  0:00:10s\n",
      "epoch 60 | loss: 0.00128 |  0:00:16s\n",
      "epoch 80 | loss: 0.00098 |  0:00:21s\n",
      "epoch 100| loss: 0.00085 |  0:00:26s\n",
      "epoch 120| loss: 0.00073 |  0:00:32s\n",
      "epoch 140| loss: 0.00052 |  0:00:37s\n",
      "epoch 160| loss: 0.0005  |  0:00:42s\n",
      "epoch 180| loss: 0.00049 |  0:00:47s\n",
      "epoch 200| loss: 0.00038 |  0:00:52s\n",
      "epoch 220| loss: 0.00036 |  0:00:57s\n",
      "epoch 240| loss: 0.00032 |  0:01:02s\n",
      "epoch 260| loss: 0.00027 |  0:01:07s\n",
      "epoch 280| loss: 0.00031 |  0:01:12s\n",
      "epoch 300| loss: 0.00025 |  0:01:18s\n",
      "epoch 320| loss: 0.00025 |  0:01:23s\n",
      "epoch 340| loss: 0.00024 |  0:01:28s\n",
      "epoch 360| loss: 0.00022 |  0:01:33s\n",
      "epoch 380| loss: 0.00021 |  0:01:39s\n",
      "epoch 400| loss: 0.0002  |  0:01:44s\n",
      "epoch 420| loss: 0.00019 |  0:01:49s\n",
      "epoch 440| loss: 0.00019 |  0:01:55s\n",
      "epoch 460| loss: 0.00019 |  0:02:00s\n",
      "epoch 480| loss: 0.00021 |  0:02:06s\n",
      "epoch 500| loss: 0.00019 |  0:02:11s\n",
      "epoch 520| loss: 0.00015 |  0:02:17s\n",
      "epoch 540| loss: 0.00015 |  0:02:22s\n",
      "epoch 560| loss: 0.00017 |  0:02:27s\n",
      "epoch 580| loss: 0.00015 |  0:02:33s\n",
      "回归评估 (Val):\n",
      "MSE: 0.001807029551765995\n",
      "MAE: 0.034671263090593436\n",
      "R²: -0.2739106573106316\n",
      "IC (val): 0.04387367893066704\n",
      "过滤高置信度样本数量:  1795\n",
      "Test Week 9 Evaluation Completed\n",
      "============================================================\n",
      "Fold 4: Train 4~9, Val 10\n",
      "Train: 2024-11-01 01:22:11.561000 to 2025-04-30 22:44:06.281000\n",
      "Val: 2025-05-01 01:03:21.868000 to 2025-05-31 19:03:01.433000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.4472  |  0:00:00s\n",
      "epoch 20 | loss: 0.00308 |  0:00:05s\n",
      "epoch 40 | loss: 0.00233 |  0:00:10s\n",
      "epoch 60 | loss: 0.00154 |  0:00:15s\n",
      "epoch 80 | loss: 0.00123 |  0:00:20s\n",
      "epoch 100| loss: 0.00086 |  0:00:25s\n",
      "epoch 120| loss: 0.0006  |  0:00:30s\n",
      "epoch 140| loss: 0.00069 |  0:00:35s\n",
      "epoch 160| loss: 0.00071 |  0:00:40s\n",
      "epoch 180| loss: 0.00052 |  0:00:45s\n",
      "epoch 200| loss: 0.00047 |  0:00:50s\n",
      "epoch 220| loss: 0.00043 |  0:00:56s\n",
      "epoch 240| loss: 0.00041 |  0:01:01s\n",
      "epoch 260| loss: 0.0004  |  0:01:06s\n",
      "epoch 280| loss: 0.00042 |  0:01:11s\n",
      "epoch 300| loss: 0.0005  |  0:01:17s\n",
      "epoch 320| loss: 0.00033 |  0:01:22s\n",
      "epoch 340| loss: 0.00028 |  0:01:27s\n",
      "epoch 360| loss: 0.00028 |  0:01:32s\n",
      "epoch 380| loss: 0.00025 |  0:01:37s\n",
      "epoch 400| loss: 0.00024 |  0:01:42s\n",
      "epoch 420| loss: 0.00028 |  0:01:47s\n",
      "epoch 440| loss: 0.00022 |  0:01:52s\n",
      "epoch 460| loss: 0.00022 |  0:01:57s\n",
      "epoch 480| loss: 0.0002  |  0:02:02s\n",
      "epoch 500| loss: 0.0002  |  0:02:07s\n",
      "epoch 520| loss: 0.00019 |  0:02:12s\n",
      "epoch 540| loss: 0.00018 |  0:02:18s\n",
      "epoch 560| loss: 0.00016 |  0:02:23s\n",
      "epoch 580| loss: 0.0002  |  0:02:28s\n",
      "回归评估 (Val):\n",
      "MSE: 0.0014885342210685763\n",
      "MAE: 0.03175983758938734\n",
      "R²: -0.329959163144689\n",
      "IC (val): 0.11745127782988213\n",
      "过滤高置信度样本数量:  849\n",
      "Test Week 10 Evaluation Completed\n",
      "============================================================\n",
      "Fold 5: Train 5~10, Val 11\n",
      "Train: 2024-12-01 01:56:59.018000 to 2025-05-31 19:03:01.433000\n",
      "Val: 2025-06-01 01:35:03.555000 to 2025-06-30 21:54:02.033000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\Grayman\\anaconda3\\envs\\EI_Lab\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.0067  |  0:00:00s\n",
      "epoch 20 | loss: 0.00294 |  0:00:04s\n",
      "epoch 40 | loss: 0.00186 |  0:00:09s\n",
      "epoch 60 | loss: 0.0012  |  0:00:13s\n",
      "epoch 80 | loss: 0.00092 |  0:00:17s\n",
      "epoch 100| loss: 0.00091 |  0:00:22s\n",
      "epoch 120| loss: 0.00068 |  0:00:26s\n",
      "epoch 140| loss: 0.00052 |  0:00:30s\n",
      "epoch 160| loss: 0.00056 |  0:00:35s\n",
      "epoch 180| loss: 0.00053 |  0:00:39s\n",
      "epoch 200| loss: 0.00039 |  0:00:43s\n",
      "epoch 220| loss: 0.00035 |  0:00:48s\n",
      "epoch 240| loss: 0.00033 |  0:00:52s\n",
      "epoch 260| loss: 0.00029 |  0:00:56s\n",
      "epoch 280| loss: 0.00032 |  0:01:01s\n",
      "epoch 300| loss: 0.00027 |  0:01:05s\n",
      "epoch 320| loss: 0.00028 |  0:01:10s\n"
     ]
    }
   ],
   "source": [
    "n_train_terms = 6 # 可配置\n",
    "n_val_terms = 1    # 一般 1 周验证\n",
    "n_test_terms = 1   # 后 1 周做 test\n",
    "\n",
    "exclude_prefixes = ['timestamp', 'timestamp_dt', 'symbol']\n",
    "target_col = \"future_return\"\n",
    "feature_cols = [\n",
    "    col for col in origin_df.columns\n",
    "    if (col.endswith(\"_zscaled\") and col.startswith(\"z_\"))\n",
    "        and all(not col.startswith(prefix) for prefix in exclude_prefixes)\n",
    "        and not col.startswith(\"future_return_\")\n",
    "        and col != \"px\"\n",
    "]\n",
    "# print(feature_cols)\n",
    "print(len(feature_cols))\n",
    "# feature_cols = [\"oi_di_long_term\"]\n",
    "results = []\n",
    "all_tab_inc_test_predictions = []\n",
    "all_tabnet_test_predictions = []\n",
    "all_lgb_test_predictions = []\n",
    "\n",
    "lgb_model = None\n",
    "tab_inc = None\n",
    "tab_inc_flag = 0\n",
    "\n",
    "overall_start = None\n",
    "overall_end = None\n",
    "\n",
    "\n",
    "for i in range(len(split_dataframes) - n_train_terms - n_val_terms + 1):\n",
    "    train_dfs = split_dataframes[i : i + n_train_terms]\n",
    "    val_dfs = split_dataframes[i + n_train_terms : i + n_train_terms + n_val_terms]\n",
    "    \n",
    "    train_df = pl.concat(train_dfs)\n",
    "    val_df = pl.concat(val_dfs)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Fold {i}: Train {i}~{i+n_train_terms-1}, Val {i+n_train_terms}\")\n",
    "    print(\"Train:\", train_df['timestamp_dt'][0], \"to\", train_df['timestamp_dt'][-1])\n",
    "    print(\"Val:\", val_df['timestamp_dt'][0], \"to\", val_df['timestamp_dt'][-1])\n",
    "\n",
    "    fold_start = train_df['timestamp_dt'][0]\n",
    "    fold_end = val_df['timestamp_dt'][-1]\n",
    "\n",
    "    # 更新 overall_start 和 overall_end\n",
    "    if overall_start is None or fold_start < overall_start:\n",
    "        overall_start = fold_start\n",
    "    if overall_end is None or fold_end > overall_end:\n",
    "        overall_end = fold_end\n",
    "        \n",
    "    # 处理 train\n",
    "    train_df_processed = train_df.sort('timestamp').drop_nulls(subset=feature_cols + [target_col, 'px']).to_pandas()\n",
    "    X_train = train_df_processed[feature_cols]\n",
    "    y_train = train_df_processed[target_col]\n",
    "    px_train = train_df_processed['px']\n",
    "    \n",
    "    # 处理 val\n",
    "    val_df_processed = val_df.sort('timestamp').drop_nulls(subset=feature_cols + [target_col, 'px']).to_pandas()\n",
    "    X_val = val_df_processed[feature_cols]\n",
    "    y_val = val_df_processed[target_col]\n",
    "    px_val = val_df_processed['px']\n",
    "    timestamps_val = val_df_processed['timestamp'] # 收集时间戳\n",
    "\n",
    "    # modellllllll\n",
    "    up_thresh = 0.2\n",
    "    lower_thresh = 0.8\n",
    "\n",
    "    # sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "    # # # #LGBM\n",
    "    # lgb_model = lgb.LGBMClassifier(n_estimators=1000, learning_rate=0.001, max_depth=4, verbose=-1)\n",
    "    # early_stopping_callback = lgb.early_stopping(\n",
    "    #     stopping_rounds=500,  # 耐心值：如果验证集性能在连续100轮内没有提升，就停止训练\n",
    "    #     verbose=True,          # 打印早停信息，例如在第多少轮停止，最佳分数是多少\n",
    "    # )\n",
    "    # lgb_model.fit(\n",
    "    #     X_train, y_train,\n",
    "    #     sample_weight=sample_weights,  # ✅ 添加 sample_weight\n",
    "    #     eval_set=[(X_val, y_val)],\n",
    "    #     eval_metric='acc',\n",
    "    #     # callbacks=[early_stopping_callback], # 将早停回调传入 callbacks 参数\n",
    "    # )\n",
    "    \n",
    "    # lgb_eval = evaluate_with_confidence(\n",
    "    #     y_true=y_val,\n",
    "    #     y_pred_proba=lgb_model.predict_proba(X_val)[:, 1],\n",
    "    #     model_name=\"lgb_model\",\n",
    "    #     lower_thresh=up_thresh,\n",
    "    #     upper_thresh=lower_thresh,\n",
    "    #     print_report=True,\n",
    "    # )\n",
    "    # # plot_last_n_rows_with_px(y_val, y_val, lgb_model.predict_proba(X_val)[:, 1], px_val, std_array=std_val, n=1, m=-1, alpha=alpha)\n",
    "    \n",
    "    # lgb_eval = evaluate_with_confidence(\n",
    "    #     y_true=y_test,\n",
    "    #     y_pred_proba=lgb_model.predict_proba(X_test)[:, 1],\n",
    "    #     model_name=\"lgb_model\",\n",
    "    #     lower_thresh=up_thresh,\n",
    "    #     upper_thresh=lower_thresh,\n",
    "    #     print_report=True,\n",
    "    # )\n",
    "    # plot_last_n_rows_with_px(lgb_model.predict_proba(X_test)[:, 1], y_test, lgb_model.predict_proba(X_test)[:, 1], px_test, std_array=std_test, n=1, m=-1, alpha=alpha)\n",
    "    # lgb_test_pred_probs = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # current_window_results = pd.DataFrame({\n",
    "    #     'timestamp': timestamps_test,\n",
    "    #     'symbol': \"BTCUSDT\", # 如果有多个股票，收集 symbol 是必要的\n",
    "    #     'true_label': y_test,\n",
    "    #     'predicted_prob': lgb_test_pred_probs,\n",
    "    #     'px': px_test, # 收集价格，回测时需要\n",
    "    #     'rolling_std': std_test # 收集波动率，可能用于策略或分析\n",
    "    #     # 添加任何你回测需要的其他数据\n",
    "    # })\n",
    "    # all_lgb_test_predictions.append(current_window_results)\n",
    "\n",
    "    # # CAT\n",
    "    # cat_model = CatBoostClassifier(iterations=2000, learning_rate=0.005, depth=9, verbose=0)\n",
    "    # cat_model.fit(\n",
    "    #     X_train, y_train_bin,\n",
    "    # )\n",
    "\n",
    "    # cat_eval = evaluate_with_confidence(\n",
    "    #     y_true=y_val_bin,\n",
    "    #     y_pred_proba=cat_model.predict_proba(X_val)[:, 1],\n",
    "    #     model_name=\"cat_model\",\n",
    "    #     lower_thresh=up_thresh,\n",
    "    #     upper_thresh=lower_thresh,\n",
    "    #     print_report=True,\n",
    "    # )\n",
    "    # plot_last_n_rows_with_px(y_val, y_val_bin, cat_model.predict_proba(X_val)[:, 1], px_val, n=6199)\n",
    "    \n",
    "    # cat_eval = evaluate_with_confidence(\n",
    "    #     y_true=y_test_bin,\n",
    "    #     y_pred_proba=cat_model.predict_proba(X_test)[:, 1],\n",
    "    #     model_name=\"cat_model\",\n",
    "    #     lower_thresh=up_thresh,\n",
    "    #     upper_thresh=lower_thresh,\n",
    "    #     print_report=True,\n",
    "    # )\n",
    "    # plot_last_n_rows_with_px(y_test, y_test_bin, cat_model.predict_proba(X_test)[:, 1], px_test, n=6199)\n",
    "\n",
    "    # # XGB\n",
    "    # xgb_model = xgb.XGBClassifier(n_estimators=2000, learning_rate=0.005, max_depth=9, verbosity=0, use_label_encoder=False)\n",
    "    # xgb_model.fit(\n",
    "    #     X_train, y_train,\n",
    "    # )\n",
    "\n",
    "    # xgb_eval = evaluate_with_confidence(\n",
    "    #     y_true=y_val,\n",
    "    #     y_pred_proba=xgb_model.predict_proba(X_val)[:, 1],\n",
    "    #     model_name=\"xgb_model\",\n",
    "    #     lower_thresh=up_thresh,\n",
    "    #     upper_thresh=lower_thresh,\n",
    "    #     print_report=True,\n",
    "    # )\n",
    "    # plot_last_n_rows_with_px(y_val, y_val, xgb_model.predict_proba(X_val)[:, 1], px_val, std_array=std_val, n=1, m=-1, alpha=alpha)\n",
    "    \n",
    "\n",
    "    # xgb_eval = evaluate_with_confidence(\n",
    "    #     y_true=y_test,\n",
    "    #     y_pred_proba=xgb_model.predict_proba(X_test)[:, 1],\n",
    "    #     model_name=\"xgb_model\",\n",
    "    #     lower_thresh=up_thresh,\n",
    "    #     upper_thresh=lower_thresh,\n",
    "    #     print_report=True,\n",
    "    # )\n",
    "    # plot_last_n_rows_with_px(y_test, y_test, xgb_model.predict_proba(X_test)[:, 1], px_test, std_array=std_test, n=1, m=-1, alpha=alpha)\n",
    "\n",
    "    params = {\n",
    "        # 模型结构参数\n",
    "        \"n_d\": 32,                      # 决策输出维度\n",
    "        \"n_a\": 32,                      # 注意力机制维度\n",
    "        \"n_steps\": 3,                  # 决策步数\n",
    "        \"gamma\": 1.3,                  # 控制特征复用的程度（>1）\n",
    "        \"n_independent\": 3,           # 每个 step 的独立 Feature Transformer 层数\n",
    "        \"n_shared\":2,                # 每个 step 的共享 Feature Transformer 层数\n",
    "    \n",
    "        # 分类特征嵌入（如果你用的都是 float 特征，可以全留空）\n",
    "        \"cat_idxs\": [],               # 类别特征的列索引\n",
    "        \"cat_dims\": [],               # 每个类别特征的类别数\n",
    "        \"cat_emb_dim\": 1,             # 类别特征的嵌入维度（或 list）\n",
    "    \n",
    "        # 正则化与数值稳定性\n",
    "        \"lambda_sparse\": 1e-5,        # 稀疏正则\n",
    "        \"epsilon\": 1e-15,             # sparsemax 稳定项\n",
    "        \"momentum\": 0.03,             # BatchNorm 的动量\n",
    "        \"clip_value\": 3.0,            # 梯度裁剪\n",
    "        \n",
    "        # 注意力 mask 类型\n",
    "        \"mask_type\": \"entmax\",     # sparsemax 或 entmax\n",
    "    \n",
    "        # 优化器设置（函数和参数）\n",
    "        # \"optimizer_fn\": torch.optim.Adam,    \n",
    "        \"optimizer_params\": {\"lr\": 1e-2},\n",
    "    \n",
    "        # 学习率调度器（可选）\n",
    "        \"scheduler_fn\": None,         # torch.optim.lr_scheduler.StepLR 等\n",
    "        \"scheduler_params\": {},       # 比如 {\"step_size\": 20, \"gamma\": 0.95}\n",
    "    \n",
    "        # 预训练解码器结构（一般用不到）\n",
    "        \"n_shared_decoder\": 1,\n",
    "        \"n_indep_decoder\": 1,\n",
    "    \n",
    "        # 训练环境和调试\n",
    "        \"seed\": 7,\n",
    "        \"verbose\": 20,\n",
    "        \"device_name\": \"cuda\",        # auto / cpu / cuda\n",
    "    }\n",
    "\n",
    "    init_fit_params = {\n",
    "        \"max_epochs\": 600,\n",
    "        \"patience\": 75,\n",
    "        \"batch_size\": 2048,\n",
    "        \"virtual_batch_size\": 512,\n",
    "    }\n",
    "\n",
    "    inc_fit_params = {\n",
    "        \"max_epochs\": 50,\n",
    "        \"patience\": 10,\n",
    "        \"batch_size\": 1024,\n",
    "        \"virtual_batch_size\": 256,\n",
    "        \"warm_start\": True,\n",
    "    }\n",
    "\n",
    "    # # Label Encode y（如果是0/1就不用）\n",
    "    # y_train_enc = y_train.astype(int)\n",
    "    # y_val_enc = y_val.astype(int)\n",
    "    \n",
    "    # sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_enc)\n",
    "    # print(sample_weights)\n",
    "    \n",
    "    # TabNet 训练\n",
    "    \n",
    "    # tabnet = TabNetClassifier(**params)\n",
    "    # tabnet.fit(\n",
    "    #     X_train=X_train.values, y_train=y_train_enc,\n",
    "    #     eval_set=[(X_val.values, y_val_enc)],\n",
    "    #     weights=sample_weights,\n",
    "    #     **init_fit_params,\n",
    "    # )\n",
    "\n",
    "    # # proba_smooth = softmax_with_temperature(proba_raw, temperature=1.5)\n",
    "    \n",
    "    # tabnet_eval = evaluate_with_confidence(\n",
    "    #     y_true=y_val,\n",
    "    #     y_pred_proba=tabnet.predict_proba(X_val.values)[:, 1],\n",
    "    #     model_name=\"tabnet\",\n",
    "    #     lower_thresh=up_thresh,\n",
    "    #     upper_thresh=lower_thresh,\n",
    "    #     print_report=True,\n",
    "    # )\n",
    "    # # plot_last_n_rows_with_px(y_val, y_val, tabnet.predict_proba(X_val.values)[:, 1], px_val, std_array=std_val, n=1, m=-1, alpha=alpha)\n",
    "\n",
    "\n",
    "    # tabnet_eval = evaluate_with_confidence(\n",
    "    #     y_true=y_test,\n",
    "    #     y_pred_proba=tabnet.predict_proba(X_test.values)[:, 1],\n",
    "    #     model_name=\"tabnet\",\n",
    "    #     lower_thresh=up_thresh,\n",
    "    #     upper_thresh=lower_thresh,\n",
    "    #     print_report=True,\n",
    "    # )\n",
    "\n",
    "    # plot_last_n_rows_with_px(y_test, y_test, tabnet.predict_proba(X_test.values)[:, 1], px_test, std_array=std_test, n=1, m=-1, alpha=alpha)\n",
    "\n",
    "    # current_window_results = pd.DataFrame({\n",
    "    #     'timestamp': timestamps_test,\n",
    "    #     'symbol': \"TST\", # 如果有多个股票，收集 symbol 是必要的\n",
    "    #     'true_label': y_test,\n",
    "    #     'predicted_prob': tabnet.predict_proba(X_test.values)[:, 1],\n",
    "    #     'px': px_test, # 收集价格，回测时需要\n",
    "    #     'rolling_std': std_test # 收集波动率，可能用于策略或分析\n",
    "    #     # 添加任何你回测需要的其他数据\n",
    "    # })\n",
    "    # all_tabnet_test_predictions.append(current_window_results)\n",
    "\n",
    "    # TabNet_incremental 训练\n",
    "    tabnet = TabNetRegressor(**params)\n",
    "    tabnet.fit(\n",
    "        X_train=X_train.values, \n",
    "        y_train=y_train.values.reshape(-1, 1),\n",
    "        **init_fit_params,\n",
    "    )\n",
    "\n",
    "    y_val_pred = tabnet.predict(X_val.values)\n",
    "    print(\"回归评估 (Val):\")\n",
    "    print(\"MSE:\", mean_squared_error(y_val, y_val_pred))\n",
    "    print(\"MAE:\", mean_absolute_error(y_val, y_val_pred))\n",
    "    print(\"R²:\", r2_score(y_val, y_val_pred))\n",
    "\n",
    "    ic, _ = spearmanr(y_val, y_val_pred)\n",
    "    print(\"IC (val):\", ic)\n",
    "    # 可选：定义置信区间（过滤极端预测）\n",
    "    conf_thresh = 0.005  # 例如：只看预测收益率 > 0.5% 或 < -0.5%\n",
    "    mask = (np.abs(y_val_pred) >= conf_thresh)\n",
    "    print(\"过滤高置信度样本数量: \", mask.sum())\n",
    "    \n",
    "    # 收集预测结果（Val 可选，Test 常用于回测）\n",
    "    current_window_results = pd.DataFrame({\n",
    "        'timestamp': timestamps_val,  # 注意：用 test 数据\n",
    "        'symbol': symbol,\n",
    "        'true_label': y_val,\n",
    "        'predicted_value': y_val_pred.ravel(),  # 保证是一维\n",
    "        'px': px_val,\n",
    "    })\n",
    "    \n",
    "    all_tab_inc_test_predictions.append(current_window_results)\n",
    "\n",
    "    week_results = {\n",
    "        'train_period': f\"{train_df['timestamp_dt'][0]} to {train_df['timestamp_dt'][-1]}\",\n",
    "        'val_period': f\"{val_df['timestamp_dt'][0]} to {val_df['timestamp_dt'][-1]}\",\n",
    "        # 'LGBM': lgb_eval,\n",
    "        # 'CatBoost': cat_model,\n",
    "        # 'XGBoost': xgb_eval,\n",
    "        # 'TabNet': tabnet_eval,\n",
    "    }\n",
    "    \n",
    "    results.append(week_results)\n",
    "    print(f\"Test Week {i+n_train_terms} Evaluation Completed\")\n",
    " \n",
    "# 存储该周评估信息\n",
    "term_results = {\n",
    "    'train_period': f\"{train_df['timestamp_dt'][0]} to {train_df['timestamp_dt'][-1]}\",\n",
    "    'val_period': f\"{val_df['timestamp_dt'][0]} to {val_df['timestamp_dt'][-1]}\",\n",
    "    'TabNet_MSE': mean_squared_error(y_val, y_val_pred),\n",
    "    'TabNet_MAE': mean_absolute_error(y_val, y_val_pred),\n",
    "    'TabNet_R2': r2_score(y_val, y_val_pred),\n",
    "    'HighConfidenceCount': int(mask.sum())\n",
    "}\n",
    "results.append(term_results)\n",
    "\n",
    "print(f\"Test Week {i + n_train_terms} Evaluation Completed\")\n",
    "\n",
    "# 合并所有窗口的预测结果\n",
    "final_predictions_df = pd.concat(all_tab_inc_test_predictions).sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Final Predictions DataFrame for Backtesting ---\")\n",
    "print(final_predictions_df.head())\n",
    "print(f\"Total rows collected: {len(final_predictions_df)}\")\n",
    "\n",
    "# 字符串化整体时间范围\n",
    "overall_start = str(overall_start)\n",
    "overall_end = str(overall_end)\n",
    "print(f\"整体训练时间范围：{overall_start} 到 {overall_end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a006a3-0037-4e37-a82a-7934dbe8d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_val.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f534f1-b2b0-4d84-bb5a-df1b68411462",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_matrix, masks = tabnet.explain(X_val.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0c07a-bc85-40b0-ba3a-d867c46b2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 explain_matrix 是 TabNetClassifier 的解释矩阵 (n_samples, n_features)\n",
    "mean_importance = np.mean(np.abs(explain_matrix), axis=0)\n",
    "top_n = 20\n",
    "top_indices = np.argsort(mean_importance)[::-1][:top_n]\n",
    "\n",
    "# 特征名\n",
    "top_feature_names = [X_train.columns[i] for i in top_indices]\n",
    "top_importance_values = mean_importance[top_indices]\n",
    "\n",
    "# 打印 Top N 特征名 + 权重\n",
    "print(f\"Top {top_n} Features by Importance:\\n\")\n",
    "for name, score in zip(top_feature_names, top_importance_values):\n",
    "    print(f\"{name:<40} Importance: {score:.6f}\")\n",
    "\n",
    "# 画图\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(range(top_n), top_importance_values)\n",
    "plt.xticks(range(top_n), top_feature_names, rotation=90)\n",
    "plt.title(f\"Top {top_n} Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed07ea1-b5c6-4fba-8e2a-7a9e0303aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mask_sample = masks[0][0]  # 第0步，第0个样本的mask\n",
    "nonzero_indices = np.nonzero(mask_sample)[0]  # 找非零位置索引\n",
    "\n",
    "print(\"被关注的特征索引:\", nonzero_indices)\n",
    "print(\"对应的权重:\", mask_sample[nonzero_indices])\n",
    "\n",
    "# 假设你的特征名列表是 feature_names（长度460）\n",
    "for idx in nonzero_indices:\n",
    "    print(f\"特征: {X_train.columns[idx]}, 权重: {mask_sample[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0fdb50-5561-4977-9544-ae1c3dcb7a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def show_tabnet_attention_masks(masks, feature_names, sample_idx=0, top_k=10):\n",
    "    \"\"\"\n",
    "    显示 TabNet 对某个样本在每一步中关注的特征及其权重。\n",
    "\n",
    "    参数:\n",
    "    - masks: tabnet.explain(X)[1] 返回的字典\n",
    "    - feature_names: list[str]，对应 X_train.columns\n",
    "    - sample_idx: 选哪个样本\n",
    "    - top_k: 最多展示前多少个非零特征\n",
    "    \"\"\"\n",
    "    for step, mask_array in masks.items():\n",
    "        mask_sample = mask_array[sample_idx]  # shape = (num_features,)\n",
    "        nonzero_indices = np.nonzero(mask_sample)[0]\n",
    "        weights = mask_sample[nonzero_indices]\n",
    "        \n",
    "        # 按照权重从高到低排序\n",
    "        sorted_idx = np.argsort(-weights)\n",
    "        top_indices = nonzero_indices[sorted_idx[:top_k]]\n",
    "        \n",
    "        print(f\"\\n🧭 Step {step}（共{len(nonzero_indices)}个非零特征）:\")\n",
    "        for i in top_indices:\n",
    "            print(f\"  特征: {feature_names[i]:<30} 权重: {mask_sample[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a9a10-0db1-469f-8630-a5297e7d1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设你已经有\n",
    "# masks = tabnet.explain(X_test)[1]\n",
    "# feature_names = list(X_test.columns)\n",
    "\n",
    "show_tabnet_attention_masks(masks, X_train.columns, sample_idx=0, top_k=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc923fa7-9359-4290-8d10-28c2d6cc4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window_size = 10\n",
    "\n",
    "final_predictions_df = pd.concat(all_tab_inc_test_predictions).sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "final_predictions_df['predicted_prob_rolling_mean'] = final_predictions_df['predicted_value'].rolling(window=rolling_window_size, min_periods=1).mean()\n",
    "final_predictions_df['predicted_prob_rolling_mean_reverse'] = 1-final_predictions_df['predicted_prob_rolling_mean']\n",
    "\n",
    "plot_last_n_rows_with_px_regression(\n",
    "    y_true=final_predictions_df['true_label'],\n",
    "    y_pred=final_predictions_df['predicted_prob_rolling_mean'],\n",
    "    px=final_predictions_df['px'],\n",
    "    n=1,\n",
    "    alpha=1.5\n",
    ")\n",
    "\n",
    "final_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1dd0c7-cb1c-430f-8817-cb23a7447f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算未来收益\n",
    "\n",
    "final_predictions_df['future_return'] = (\n",
    "    final_predictions_df['px'].shift(-future_window) / final_predictions_df['px'] - 1\n",
    ")\n",
    "\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "signal_col = 'predicted_value'\n",
    "return_col = 'future_return'\n",
    "\n",
    "ic_df = final_predictions_df[[signal_col, return_col]].dropna()\n",
    "rank_ic, p_value = spearmanr(ic_df[signal_col], ic_df[return_col])\n",
    "\n",
    "print(f\"Rank IC: {rank_ic:.4f}, p-value: {p_value:.4g}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24f04a-8786-48e1-925f-604cb622b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 原始 predict_proba 分布\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(final_predictions_df['predicted_value'][200:], bins=15, alpha=0.7, color='skyblue')\n",
    "plt.title('Predicted Probability Distribution')\n",
    "plt.xlabel('Predicted Prob')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 滚动均值分布\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(final_predictions_df['predicted_prob_rolling_mean'][200:], bins=15, alpha=0.7, color='lightcoral')\n",
    "plt.title('Rolling Mean of Predicted Probabilities')\n",
    "plt.xlabel('Rolling Mean Prob')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3055032-38ac-490c-8e25-9a102aa02039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "ma_window = int(feat_norm_rolling_mean_window)\n",
    "# ma_window = 200\n",
    "\n",
    "all_predictions_df = final_predictions_df\n",
    "all_predictions_df['timestamp'] = pd.to_datetime(all_predictions_df['timestamp'], unit='us') # Assuming microseconds\n",
    "all_predictions_df['ma'] = all_predictions_df['px'].rolling(window=ma_window).mean()\n",
    "\n",
    "symbol_to_backtest = all_predictions_df['symbol'].iloc[0] # Take the first symbol for now\n",
    "df = all_predictions_df[all_predictions_df['symbol'] == symbol_to_backtest].copy()\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# ===============================================\n",
    "# Backtesting Parameters (Ratios for costs)\n",
    "# ===============================================\n",
    "initial_capital = 100000  # Initial capital\n",
    "commission_ratio = 0.0005 # Commission ratio (e.0.05%)\n",
    "slippage_ratio = 0.0007   # Slippage ratio (e.g., 0.02%)\n",
    "\n",
    "trade_size_ratio = 0.9    # Percentage of current equity to allocate per trade\n",
    "\n",
    "# Strategy Thresholds (needs optimization)\n",
    "long_threshold = 0.035 # Predicted probability above this to go long (buy)\n",
    "short_threshold = -0.035 # Predicted probability below this to go short (sell)\n",
    "\n",
    "beta = 5\n",
    "# Dynamic Take Profit / Stop Loss (in multiples of rolling_std/px)\n",
    "long_stop_loss_multiplier = beta\n",
    "long_take_profit_multiplier = beta\n",
    "short_stop_loss_multiplier = beta\n",
    "short_take_profit_multiplier = beta\n",
    "\n",
    "# ===============================================\n",
    "# Backtesting Main Logic (No change here from previous version)\n",
    "# ===============================================\n",
    "\n",
    "# Initialize account state\n",
    "capital = initial_capital\n",
    "position = 0          # Position size (positive for long, negative for short, 0 for flat)\n",
    "entry_price = 0       # Entry price for current position\n",
    "realized_pnl = 0      # Realized PnL from closed trades\n",
    "equity_curve = [initial_capital] # Equity curve\n",
    "unrealized_pnl_series = [0]\n",
    "\n",
    "# Record trades\n",
    "trades = []\n",
    "\n",
    "step = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    current_time = df['timestamp'].iloc[i]\n",
    "    current_px = df['px'].iloc[i]\n",
    "    predicted_prob = df['predicted_prob_rolling_mean'].iloc[i]\n",
    "    ma = df['ma'].iloc[i]\n",
    "    current_rolling_std = current_px * 0.01\n",
    "    # Calculate current total equity (capital + market value of position)\n",
    "    if position > 0: # Long position\n",
    "        unrealized_pnl = (current_px - entry_price) * position\n",
    "    elif position < 0: # Short position\n",
    "        unrealized_pnl = (entry_price - current_px) * abs(position) # Profit when price falls\n",
    "    else: # Flat\n",
    "        unrealized_pnl = 0\n",
    "\n",
    "    current_equity = capital + unrealized_pnl\n",
    "    equity_curve.append(current_equity)\n",
    "    unrealized_pnl_series.append(unrealized_pnl)\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # Strategy Execution - Long-Short\n",
    "    # -----------------------------------------------\n",
    "\n",
    "    # Scenario 1: Currently FLAT (position == 0)\n",
    "    if position == 0:\n",
    "        if predicted_prob >= long_threshold: # Go Long Signal\n",
    "            trade_type = 'BUY_OPEN'\n",
    "            trade_price = current_px * (1 + slippage_ratio)\n",
    "            num_shares = (current_equity * trade_size_ratio) / (trade_price * (1 + commission_ratio))\n",
    "\n",
    "            if num_shares > 0:\n",
    "                position = num_shares\n",
    "                entry_price = trade_price\n",
    "                # capital -= (position * entry_price * (1 + commission_ratio))\n",
    "\n",
    "                trades.append({\n",
    "                    'timestamp': current_time, 'type': trade_type, 'price': entry_price, 'shares': position,\n",
    "                    'capital_after_trade': capital, 'equity_after_trade': current_equity, 'predicted_prob': predicted_prob\n",
    "                })\n",
    "                print(f\"{current_time}: {trade_type} {position:.2f} @ {entry_price:.2f} (Prob: {predicted_prob:.4f}) | Capital: {capital:.2f}\")\n",
    "\n",
    "        elif predicted_prob <= short_threshold: # Go Short Signal\n",
    "            trade_type = 'SELL_SHORT_OPEN'\n",
    "            trade_price = current_px * (1 - slippage_ratio) # Price for short is lower (sell at market)\n",
    "            num_shares = (current_equity * trade_size_ratio) / (trade_price * (1 + commission_ratio))\n",
    "\n",
    "            if num_shares > 0:\n",
    "                position = -num_shares # Negative for short position\n",
    "                entry_price = trade_price\n",
    "                # capital -= (abs(position) * entry_price * (1 + commission_ratio))\n",
    "\n",
    "                trades.append({\n",
    "                    'timestamp': current_time, 'type': trade_type, 'price': entry_price, 'shares': position,\n",
    "                    'capital_after_trade': capital, 'equity_after_trade': current_equity, 'predicted_prob': predicted_prob\n",
    "                })\n",
    "                print(f\"{current_time}: {trade_type} {position:.2f} @ {entry_price:.2f} (Prob: {predicted_prob:.4f}) | Capital: {capital:.2f}\")\n",
    "\n",
    "    # Scenario 2: Currently LONG (position > 0)\n",
    "    elif position > 0:\n",
    "        sl_price = entry_price - long_stop_loss_multiplier * current_rolling_std\n",
    "        tp_price = entry_price + long_take_profit_multiplier * current_rolling_std\n",
    "\n",
    "        should_close = False\n",
    "        reason = \"\"\n",
    "\n",
    "        step += 1\n",
    "        \n",
    "        if current_px <= sl_price:\n",
    "            should_close = True\n",
    "            reason = \"Long Stop Loss Hit\"\n",
    "        elif current_px >= tp_price:\n",
    "            should_close = True\n",
    "            reason = \"Long Take Profit Hit\"\n",
    "\n",
    "        if should_close or step > future_window:\n",
    "            step = 0\n",
    "            trade_type = 'SELL_CLOSE_LONG'\n",
    "            close_price = current_px * (1 - slippage_ratio)\n",
    "            gross_pnl_on_trade = (close_price - entry_price) * position\n",
    "            net_pnl_on_trade = gross_pnl_on_trade - (close_price * position * commission_ratio)\n",
    "\n",
    "            realized_pnl += net_pnl_on_trade\n",
    "            capital += net_pnl_on_trade\n",
    "\n",
    "            trades.append({\n",
    "                'timestamp': current_time, 'type': trade_type, 'price': close_price, 'shares': position,\n",
    "                'pnl': net_pnl_on_trade, 'capital_after_trade': capital, 'equity_after_trade': current_equity,\n",
    "                'reason': reason, 'predicted_prob': predicted_prob\n",
    "            })\n",
    "            print(f\"{current_time}: {trade_type} {position:.2f} @ {close_price:.2f} | PnL: {net_pnl_on_trade:.2f} | Capital: {capital:.2f} | Reason: {reason}\")\n",
    "            \n",
    "            position = 0\n",
    "            entry_price = 0\n",
    "\n",
    "\n",
    "    # Scenario 3: Currently SHORT (position < 0)\n",
    "    elif position < 0:\n",
    "        sl_price = entry_price + long_stop_loss_multiplier * current_rolling_std\n",
    "        tp_price = entry_price - long_take_profit_multiplier * current_rolling_std\n",
    "\n",
    "        should_close = False\n",
    "        reason = \"\"\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        if current_px >= sl_price:\n",
    "            should_close = True\n",
    "            reason = \"Short Stop Loss Hit\"\n",
    "        elif current_px <= tp_price:\n",
    "            should_close = True\n",
    "            reason = \"Short Take Profit Hit\"\n",
    "\n",
    "        if should_close or step > future_window:\n",
    "            step = 0\n",
    "\n",
    "            trade_type = 'BUY_TO_COVER_SHORT'\n",
    "            close_price = current_px * (1 + slippage_ratio)\n",
    "            gross_pnl_on_trade = (entry_price - close_price) * abs(position)\n",
    "            net_pnl_on_trade = gross_pnl_on_trade - (close_price * abs(position) * commission_ratio)\n",
    "\n",
    "            realized_pnl += net_pnl_on_trade\n",
    "            capital += net_pnl_on_trade\n",
    "\n",
    "            trades.append({\n",
    "                'timestamp': current_time, 'type': trade_type, 'price': close_price, 'shares': position,\n",
    "                'pnl': net_pnl_on_trade, 'capital_after_trade': capital, 'equity_after_trade': current_equity,\n",
    "                'reason': reason, 'predicted_prob': predicted_prob\n",
    "            })\n",
    "            print(f\"{current_time}: {trade_type} {abs(position):.2f} @ {close_price:.2f} | PnL: {net_pnl_on_trade:.2f} | Capital: {capital:.2f} | Reason: {reason}\")\n",
    "\n",
    "            position = 0\n",
    "            entry_price = 0\n",
    "\n",
    "# Final close-out at the end of backtest if any position is open\n",
    "final_equity_append_time = df['timestamp'].iloc[-1] + pd.Timedelta(seconds=1)\n",
    "if position != 0:\n",
    "    last_px = df['px'].iloc[-1]\n",
    "    if position > 0: # Close long\n",
    "        final_close_price = last_px * (1 - slippage_ratio)\n",
    "        gross_pnl_on_trade = (final_close_price - entry_price) * position\n",
    "        net_pnl_on_trade = gross_pnl_on_trade - (final_close_price * position * commission_ratio)\n",
    "        # capital += (position * final_close_price * (1 - commission_ratio))\n",
    "        trades.append({\n",
    "            'timestamp': final_equity_append_time, 'type': 'SELL_FINAL_LONG', 'price': final_close_price, 'shares': position,\n",
    "            'pnl': net_pnl_on_trade, 'capital_after_trade': capital, 'equity_after_trade': equity_curve[-1],\n",
    "            'reason': 'End of Backtest', 'predicted_prob': df['predicted_value'].iloc[-1]\n",
    "        })\n",
    "        # print(f\"End of Backtest: SELL_FINAL_LONG {position:.2f} @ {final_close_price:.2f} | PnL: {net_pnl_on_trade:.2f} | Capital: {capital:.2f}\")\n",
    "    else: # Close short\n",
    "        final_close_price = last_px * (1 + slippage_ratio)\n",
    "        gross_pnl_on_trade = (entry_price - final_close_price) * abs(position)\n",
    "        net_pnl_on_trade = gross_pnl_on_trade - (final_close_price * abs(position) * commission_ratio)\n",
    "        # capital += (abs(position) * entry_price * (1 - commission_ratio))\n",
    "        trades.append({\n",
    "            'timestamp': final_equity_append_time, 'type': 'BUY_FINAL_SHORT', 'price': final_close_price, 'shares': position,\n",
    "            'pnl': net_pnl_on_trade, 'capital_after_trade': capital, 'equity_after_trade': equity_curve[-1],\n",
    "            'reason': 'End of Backtest', 'predicted_prob': df['predicted_value'].iloc[-1]\n",
    "        })\n",
    "        # print(f\"End of Backtest: BUY_FINAL_SHORT {abs(position):.2f} @ {final_close_price:.2f} | PnL: {net_pnl_on_trade:.2f} | Capital: {capital:.2f}\")\n",
    "    realized_pnl += net_pnl_on_trade\n",
    "    position = 0\n",
    "\n",
    "# Final equity curve update\n",
    "equity_curve[-1] = capital\n",
    "unrealized_pnl_series[-1] = 0\n",
    "# ===============================================\n",
    "# Performance Metrics Calculation (KEY CHANGES HERE)\n",
    "# ===============================================\n",
    "equity_series = pd.Series(equity_curve, index=df['timestamp'].tolist() + [final_equity_append_time])\n",
    "returns = equity_series.pct_change().dropna()\n",
    "unrealized_pnl_series = pd.Series(unrealized_pnl_series, index=equity_series.index)\n",
    "\n",
    "# Total Return\n",
    "total_return = (capital - initial_capital) / initial_capital\n",
    "\n",
    "# Annualized Return - Based on Total Duration\n",
    "annualized_return = total_return # Default value if not enough data\n",
    "\n",
    "if len(df) > 1:\n",
    "    # Get the total duration of the backtest data\n",
    "    total_duration = df['timestamp'].iloc[-1] - df['timestamp'].iloc[0]\n",
    "    total_duration_seconds = total_duration.total_seconds()\n",
    "\n",
    "    if total_duration_seconds > 0:\n",
    "        # Number of seconds in a year\n",
    "        seconds_in_year = 365 * 24 * 60 * 60\n",
    "\n",
    "        # Annualization factor: (seconds in a year) / (total seconds in backtest)\n",
    "        annualization_factor = seconds_in_year / total_duration_seconds\n",
    "\n",
    "        # Apply annualization\n",
    "        annualized_return = (1 + total_return)**annualization_factor - 1\n",
    "    else:\n",
    "        print(\"Warning: Total backtest duration is zero or invalid, cannot annualize return.\")\n",
    "else:\n",
    "    print(\"Warning: Not enough data points to calculate total duration for annualization.\")\n",
    "\n",
    "\n",
    "# Max Drawdown\n",
    "peak = equity_series.expanding(min_periods=1).max()\n",
    "drawdown = (equity_series - peak) / peak\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "# Sharpe Ratio (assuming risk-free rate is 0)\n",
    "# For volatility, we use returns.std() and annualize it with the same factor\n",
    "annualized_volatility = returns.std() * np.sqrt(annualization_factor) if 'annualization_factor' in locals() and annualization_factor > 0 else returns.std()\n",
    "sharpe_ratio = annualized_return / annualized_volatility if annualized_volatility != 0 else np.nan\n",
    "\n",
    "# Win Rate for closed trades\n",
    "if len(trades) > 0:\n",
    "    winning_trades = sum(1 for t in trades if 'pnl' in t and t['pnl'] > 0)\n",
    "    total_closed_trades = sum(1 for t in trades if 'pnl' in t)\n",
    "    win_rate = winning_trades / total_closed_trades if total_closed_trades > 0 else 0\n",
    "else:\n",
    "    win_rate = 0\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Backtesting Results Summary (Long-Short Strategy):\")\n",
    "print(f\"Initial Capital: {initial_capital:.2f}\")\n",
    "print(f\"Final Capital: {capital:.2f}\")\n",
    "print(f\"Total Return: {total_return:.2%}\")\n",
    "print(f\"Total Realized PnL: {realized_pnl:.2f}\")\n",
    "print(f\"年化收益 (近似): {annualized_return:.2%}\")\n",
    "print(f\"Maximum Drawdown: {max_drawdown:.2%}\")\n",
    "print(f\"Sharpe Ratio (Risk-Free Rate = 0): {sharpe_ratio:.2f}\")\n",
    "print(f\"Number of Trades: {len(trades)}\")\n",
    "print(f\"Win Rate: {win_rate:.2%}\")\n",
    "print(\"=\"*60)\n",
    "print(\"ma\")\n",
    "\n",
    "# ===============================================\n",
    "# Plotting\n",
    "# ===============================================\n",
    "\n",
    "# Equity Curve\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(equity_series.index, equity_series, label='Equity Curve')\n",
    "plt.title(f'{symbol_to_backtest} Long-Short Strategy Equity Curve')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Equity')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Returns Distribution\n",
    "if not returns.empty:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(returns, kde=True, bins=50)\n",
    "    plt.title(f'{symbol_to_backtest} Returns Distribution')\n",
    "    plt.xlabel('Return')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Drawdown Plot\n",
    "if not drawdown.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(drawdown.index, drawdown, label='Drawdown')\n",
    "    plt.fill_between(drawdown.index, drawdown, 0, where=(drawdown < 0), color='red', alpha=0.3)\n",
    "    plt.title(f'{symbol_to_backtest} Drawdown')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Drawdown (%)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(unrealized_pnl_series.index, unrealized_pnl_series, label=\"Unrealized PnL\")\n",
    "# plt.axhline(0, color='gray', linestyle='--')\n",
    "# plt.title(f\"{symbol_to_backtest} 浮动盈亏 (Unrealized PnL)\")\n",
    "# plt.xlabel(\"Timestamp\")\n",
    "# plt.ylabel(\"Unrealized PnL\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd4dc2-5dea-4d22-9da7-f5b19fbe3535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EI_Lab)",
   "language": "python",
   "name": "ei_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
